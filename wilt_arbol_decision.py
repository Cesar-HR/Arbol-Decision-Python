# -*- coding: utf-8 -*-
"""Wilt_AD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HkTVt8yI8OkCfx2AWODkGldTZ0bp6U7C

# Árbol de decisión (AD)

Base de datos: **Wilt Data Set**

Descripción:

```
Conjunto de datos de teledetección de alta resolución (Quickbird). Pequeño número de muestras de entrenamiento de árboles enfermos, gran número para otras cubiertas del suelo. Conjunto de datos de prueba a partir de una muestra aleatoria estratificada de imágenes.

class: 'w' (diseased trees), 'n' (all other land cover)
GLCM_Pan: GLCM mean texture (Pan band)
Mean_G: Mean green value
Mean_R: Mean red value
Mean_NIR: Mean NIR value
SD_Pan: Standard deviation (Pan band)
```
"""

import pandas as pd
# Extraemos la información del file csv
training = pd.read_csv("Wilt.csv")
# Detalles de la base de datos
training.info()
# Tabla con los 5 primeros datos
training.head(5)

# Aplicamos condicional:
# n (all other land cover) - 0
# w (diseased trees) - 1
training["class"] = training["class"].apply(lambda toLabel: 0 if toLabel == "n" else 1)
# Tabla con los 5 primeros datos
training.head(5)

# Asignamos las columnas a considerar a una variable
columns = ["class", "GLCM_pan", "Mean_Green", "Mean_Red", "Mean_NIR", "SD_pan"]
# Asignamos los valores de columns a datosIniciales
datosIniciales = training[list(columns)]
#Tabla con los 5 primeros datos
datosIniciales.head(5)

datosIniciales.shape

# Asignamos las columnas a considerar a una variable
columns = ["GLCM_pan", "Mean_Green", "Mean_Red", "Mean_NIR", "SD_pan"]
# X_input representa los valores de entrada
X_input = datosIniciales[list(columns)].values
# Y_Target representa los valores de salida deseadas
Y_target = datosIniciales["class"].values

"""**Árbol de desición - con profundidad definida**"""

# Con profundidad definida
from sklearn import tree

# Creamos clf_train_depth como objeto clasificador de árbol de decisión
clf_train_depth = tree.DecisionTreeClassifier(criterion="entropy", max_depth=5)

# Entrenamos el modelo mediante el método fit() del objeto árbol de decisión. 
# Suministramos al método la variable de entrada X_input y la variable de destino Y_target
clf_train_depth = clf_train_depth.fit(X_input, Y_target)

# Respuesta: 0.9951601751555658 - con profundidad definida (5)
clf_train_depth.score(X_input,Y_target)

import six
with open("Wilt_depth.dot", 'w') as f:
  f = tree.export_graphviz(clf_train_depth, out_file=f, feature_names=columns)

!dot -Tpng ./Wilt_depth.dot -o ./Wilt_depth.png

from IPython.display import Image
# Mostramos el gráfico del árbol de decisiones
Image("Wilt_depth.png")

"""**Árbol de desición - con profundidad sin definir**"""

# Con profundidad sin definir
from sklearn import tree

# Creamos clf_train como objeto clasificador de árbol de decisión
clf_train = tree.DecisionTreeClassifier(criterion="entropy")

# Entrenamos el modelo mediante el método fit() del objeto árbol de decisión. 
# Suministramos al método la variable de entrada X_input y la variable de destino Y_target
clf_train = clf_train.fit(X_input, Y_target)

# Respuesta: 1.0 - con profundidad sin definir
clf_train.score(X_input,Y_target)

with open("Wilt.dot", 'w') as f:
  f = tree.export_graphviz(clf_train, out_file=f, feature_names=columns)

!dot -Tpng ./Wilt.dot -o ./Wilt.png

from IPython.display import Image
# Mostramos el gráfico del árbol de decisiones
Image("Wilt.png")

"""**Árbol de desición - testing**"""

# Extraemos la información del file csv
testing = pd.read_csv("Wilt_test.csv")

# Aplicamos condicional:
# n (all other land cover) - 0
# w (diseased trees) - 1
testing["class"] = testing["class"].apply(lambda toLabel: 0 if toLabel == "n" else 1)
# Tabla con los 5 primeros datos
testing.head(5)

# Asignamos las columnas a considerar a una variable
columns2 = ["class", "GLCM_pan", "Mean_Green", "Mean_Red", "Mean_NIR", "SD_pan"]
# Asignamos los valores de columns a datosInicialesTesting
datosInicialesTesting = testing[list(columns2)]

# Asignamos las columnas a considerar a una variable
columns2 = ["GLCM_pan", "Mean_Green", "Mean_Red", "Mean_NIR", "SD_pan"]
# X_input representa los valores de entrada
X_inputTesting = datosInicialesTesting[list(columns2)].values
# Y_Target representa los valores de salida deseadas
Y_targetTesting = datosInicialesTesting["class"].values

# Con profunidad definida (max_depth = 5)
target_labelTesting_depth = clf_train_depth.predict(X_inputTesting)
# Con profunidad sin definir
target_labelTesting = clf_train.predict(X_inputTesting)

print(Y_targetTesting.shape)
print(target_labelTesting_depth.shape)
print(target_labelTesting.shape)

import numpy as np
# Con profunidad definida (max_depth = 5)
acc_depth = np.sum(Y_targetTesting == target_labelTesting_depth)/float(len(target_labelTesting_depth))
print("Con profunidad definida: ",acc_depth)
# Con profunidad sin definir
acc = np.sum(Y_targetTesting == target_labelTesting)/float(len(target_labelTesting))
print("Con profunidad sin definir: ",acc)

"""**Caso Prueba - Con profundidad definida**"""

output_depth = clf_train_depth.predict([[120.3627737,205.5,119.3953488,416.5813953,20.67631835]])
print(output_depth) # expected output (w - 1)

"""**Caso Prueba - Con profundidad sin definir**"""

output = clf_train.predict([[109.8285714,183.7,82.95,251.75,16.0794123]])
print(output) # expected output (n - 0)